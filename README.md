# ODverse33
Newer YOLO versions are not always better!    
**ODverse33** is a comprehensive benchmark that includes **33 datasets** spanning **11 diverse domains** :

<table>
  <tr>
    <td>Autonomous Driving</td>
    <td>Agricultural</td>
    <td>Underwater</td>
  </tr>
  <tr>
    <td>Medical</td>
    <td>Videogame</td>
    <td>Industrial</td>
  </tr>
  <tr>
    <td>Aerial</td>
    <td>Wildlife</td>
    <td>Retail</td>
  </tr>
  <tr>
    <td>Microscopic</td>
    <td>Security</td>
    <td></td>
  </tr>
</table>
It provides a **multi-domain evaluation** for YOLO models, ranging from **YOLOv5 to YOLOv11**.

Our paper, **"ODVerse33: Is the New YOLO Version Always Better? A Multi-Domain Benchmark from YOLO v5 to v11"**, is now available on [*ArXiv*](http://arxiv.org/abs/2502.14314).



A Timeline of YOLO series detectors from v1 to v11:    

<p align="left">
  <img src="https://github.com/user-attachments/assets/e9befecb-a13d-44c7-b1d4-51c0fbeac3f1" width="100%" height="auto">
</p>    

Results on our validation and test data/ or on the COCO validation set (traditionally):
<p align="left">
  <img src="https://github.com/user-attachments/assets/296d5550-90f0-4205-9d5b-e7b9545aed4a" width="800" height="auto">
</p>    

Overall result on the test sets in ODverse33 (averaged on 11 domains):
<p align="left">
  <img src="https://github.com/user-attachments/assets/7830d3e1-19ae-477b-9565-faa515b378d8" width="80%" height="auto">
</p>



    
More detailed results for 11 diverse domains and 33 datasets can be found in the paper.





